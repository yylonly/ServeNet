{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[View in Colaboratory](https://colab.research.google.com/github/yylonly/ServeNet/blob/master/4_ServeNet_2D_CNN_1_BI_LTSM(512)_FC_(Glove200b_trainedEmbeddingLayer).ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6hoa1DP1WkII"
   },
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "XfI1Vo4OMT2Z",
    "outputId": "40b30011-55a2-409f-8275-88b45863d3a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "seed = 12345\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "# The below is necessary in Python 3.2.3 onwards to\n",
    "# have reproducible behavior for certain hash-based operations.\n",
    "# See these references for further details:\n",
    "# https://docs.python.org/3.4/using/cmdline.html#envvar-PYTHONHASHSEED\n",
    "# https://github.com/keras-team/keras/issues/2280#issuecomment-306959926\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "\n",
    "rn.seed(seed)\n",
    "\n",
    "# Force TensorFlow to use single thread.\n",
    "# Multiple threads are a potential source of\n",
    "# non-reproducible results.\n",
    "# For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
    "\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "# The below tf.set_random_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "# Rest of code follows ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qL_9yWOQWkIS"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras import metrics\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, Conv2D, Reshape, Average, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.initializers import Orthogonal\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "bpfEzZ-6WkIb",
    "outputId": "b85576bb-11ed-4d82-9800-f365305d6611"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8123, 110) (8123, 50)\n",
      "(2061, 110) (2061, 50)\n"
     ]
    }
   ],
   "source": [
    "h5f = h5py.File('../Data/SplittedPaddedIndexedServiceDataset.h5','r') \n",
    "X_train = h5f['indexed_padded_Train_X'][:]\n",
    "Y_train = h5f['Train_Y_one_hot'][:]\n",
    "X_test = h5f['indexed_padded_Test_X'][:]\n",
    "Y_test = h5f['Test_Y_one_hot'][:]\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "zhVSbkpqWkIg",
    "outputId": "850dac5b-d157-4c19-d250-0adb9701a02d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([357266, 146233, 306318,  68100, 268046, 340949, 226138, 192973,\n",
       "       269953, 268046,   8172, 304244, 306318,  68159, 188481, 357266,\n",
       "       146211, 350362, 357266, 306262, 126057, 268046, 357266,  68100,\n",
       "       225650, 360915, 293378, 297112, 133215, 306262,  54718, 108280,\n",
       "       360915, 133215, 287783, 125166, 188481, 348215, 268046, 358160,\n",
       "       163265, 193716, 174032, 111449,  57488, 357212, 220870, 122453,\n",
       "        45107, 357266, 117493, 343876, 269798, 193919, 384515, 333113,\n",
       "       357266, 153371,  57459, 220930, 374205, 297544, 357266, 146233,\n",
       "       306318, 133215, 117493, 153371,  54718,  58800, 146233, 306318,\n",
       "       133215, 117493,  51203, 117505, 360915, 306966, 339034, 117493,\n",
       "       357266, 306162, 117493,  90548,  71090, 114153,  45217, 360915,\n",
       "       117493, 338227, 305005,  93724, 325550,  54718, 272583, 291376,\n",
       "       357266,  57459, 374208, 306616,  89943,  54718, 306550,  58997,\n",
       "       151766, 188481, 392023,      0,      0,      0], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "FLYgnhNJWkIk",
    "outputId": "25daa7f4-82dc-4eee-c1fe-50929d260ac7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ServeNet - Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gc4ACh8PWkIn"
   },
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r', encoding=\"utf-8\") as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LIg9DNAKWkIp"
   },
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('../Data/glove.6B.200d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sB4JhYhdWkIr"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: pretrained_embedding_layer\n",
    "\n",
    "def trainable_embedding_layer():\n",
    "    \"\"\"\n",
    "    Creates a Keras Embedding() layer and loads in pre-trained GloVe 50-dimensional vectors.\n",
    "    \n",
    "    Arguments:\n",
    "    word_to_vec_map -- dictionary mapping words to their GloVe vector representation.\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    embedding_layer -- pretrained layer Keras instance\n",
    "    \"\"\"\n",
    "    vocab_len = len(word_to_index) + 1                  # adding 1 to fit Keras embedding (requirement)\n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]      # define dimensionality of your GloVe word vectors (= 50)\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Initialize the embedding matrix as a numpy array of zeros of shape (vocab_len, dimensions of word vectors = emb_dim)\n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    \n",
    "    # Set each row \"index\" of the embedding matrix to be the word vector representation of the \"index\"th word of the vocabulary\n",
    "    for word, index in word_to_index.items():\n",
    "        embedding_vector = word_to_vec_map.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            emb_matrix[index, :] = embedding_vector\n",
    "\n",
    "    # Define Keras embedding layer with the correct output/input sizes, make it trainable. Use Embedding(...). Make sure to set trainable=False. \n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Build the embedding layer, it is required before setting the weights of the embedding layer. Do not modify the \"None\".\n",
    "    embedding_layer.build((None,))\n",
    "    \n",
    "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5GcRUNge-fIJ"
   },
   "outputs": [],
   "source": [
    "def CNN(input_shape):\n",
    "    \"\"\"\n",
    "    Function creating the Emojify-v2 model's graph.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the input, usually (max_len,)\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    model -- a model instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Define sentence_indices as the input of the graph, it should be of shape input_shape and dtype 'int32' (as it contains indices).\n",
    "    sentence_indices = Input(shape=input_shape, dtype='int32')\n",
    "    \n",
    "    # Create the embedding layer pretrained with GloVe Vectors (â‰ˆ1 line)\n",
    "    embedding_layer = trainable_embedding_layer()\n",
    "    \n",
    "    # Propagate sentence_indices through your embedding layer, you get back the embeddings\n",
    "    embeddings = embedding_layer(sentence_indices) \n",
    "     \n",
    "    embeddings = Reshape((110, 200, 1))(embeddings)\n",
    "    \n",
    "    cnn1 = Conv2D(128, kernel_size=(5, 5), padding='same', kernel_initializer=glorot_uniform(seed=seed))(embeddings)\n",
    "    cnn1 = Dropout(0.6, seed = seed)(cnn1)\n",
    "    cnn2 = Conv2D(64, kernel_size=(3, 3), padding='same', kernel_initializer=glorot_uniform(seed=seed))(cnn1)\n",
    "    cnn2 = Dropout(0.6, seed = seed)(cnn2)\n",
    "    cnn3 = Conv2D(1, kernel_size=(1, 1), padding='same', kernel_initializer=glorot_uniform(seed=seed))(cnn2)\n",
    "    features_cnn = Reshape((110, 200))(cnn3)\n",
    "     \n",
    "    flat = Flatten()(features_cnn)  \n",
    "      \n",
    "    # Propagate X through a Dense layer with softmax activation to get back a batch of 5-dimensional vectors.\n",
    "    X = Dense(1024, activation='tanh', kernel_initializer=glorot_uniform(seed))(flat)\n",
    "    X = Dropout(0.6, seed = seed)(X)\n",
    "    X = Dense(400, activation='tanh', kernel_initializer=glorot_uniform(seed))(X)\n",
    "    X = Dropout(0.6, seed = seed)(X)\n",
    "    X = Dense(50, activation='softmax', kernel_initializer=glorot_uniform(seed))(X)\n",
    "    \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(inputs=sentence_indices, outputs=X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zi1efnBBWkIz"
   },
   "outputs": [],
   "source": [
    "maxLen = 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "i7qu9vaZWkI1",
    "outputId": "e6843c07-d31b-4146-8e63-11528487956b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 110)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 110, 200)          80000200  \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 110, 200, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 110, 200, 128)     3328      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 110, 200, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 110, 200, 64)      73792     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 110, 200, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 110, 200, 1)       65        \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 110, 200)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 22000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              22529024  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 400)               410000    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                20050     \n",
      "=================================================================\n",
      "Total params: 103,036,459\n",
      "Trainable params: 23,036,259\n",
      "Non-trainable params: 80,000,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = CNN((maxLen, ))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6732
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "10oB60NRHL4l",
    "outputId": "8c995471-9afd-4a52-c91b-17175d8c63cf"
   },
   "outputs": [],
   "source": [
    "#for i in range(len(model.layers)):\n",
    "#  print(model.layers[i].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6732
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "4GuzvnVPHuW0",
    "outputId": "677240f8-b04f-49bc-a87b-4fa100182215"
   },
   "outputs": [],
   "source": [
    "#for i in range(len(model.layers)):\n",
    "#  print(model.layers[i].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='../Data/CNN.hdf5', monitor='val_top_k_categorical_accuracy', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t73LUk-ygRTg"
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i4d23SNMWkI7"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[metrics.top_k_categorical_accuracy, metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 19865
    },
    "colab_type": "code",
    "id": "DZDiB4UMXVcG",
    "outputId": "ed85325f-d7f7-407d-8778-3856d067dafd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8123 samples, validate on 2061 samples\n",
      "Epoch 1/20\n",
      "8123/8123 [==============================] - 44s 5ms/step - loss: 4.1339 - top_k_categorical_accuracy: 0.1902 - categorical_accuracy: 0.0515 - val_loss: 3.5747 - val_top_k_categorical_accuracy: 0.3523 - val_categorical_accuracy: 0.1218\n",
      "\n",
      "Epoch 00001: val_top_k_categorical_accuracy improved from -inf to 0.35226, saving model to ../Data/CNN.hdf5\n",
      "Epoch 2/20\n",
      "8123/8123 [==============================] - 39s 5ms/step - loss: 3.5617 - top_k_categorical_accuracy: 0.3968 - categorical_accuracy: 0.1480 - val_loss: 3.1965 - val_top_k_categorical_accuracy: 0.4813 - val_categorical_accuracy: 0.2111\n",
      "\n",
      "Epoch 00002: val_top_k_categorical_accuracy improved from 0.35226 to 0.48132, saving model to ../Data/CNN.hdf5\n",
      "Epoch 3/20\n",
      "8123/8123 [==============================] - 39s 5ms/step - loss: 2.4550 - top_k_categorical_accuracy: 0.6722 - categorical_accuracy: 0.3510 - val_loss: 3.0097 - val_top_k_categorical_accuracy: 0.5400 - val_categorical_accuracy: 0.2591\n",
      "\n",
      "Epoch 00003: val_top_k_categorical_accuracy improved from 0.48132 to 0.54003, saving model to ../Data/CNN.hdf5\n",
      "Epoch 4/20\n",
      "8123/8123 [==============================] - 39s 5ms/step - loss: 1.6011 - top_k_categorical_accuracy: 0.8471 - categorical_accuracy: 0.5599 - val_loss: 3.1323 - val_top_k_categorical_accuracy: 0.5696 - val_categorical_accuracy: 0.2649\n",
      "\n",
      "Epoch 00004: val_top_k_categorical_accuracy improved from 0.54003 to 0.56963, saving model to ../Data/CNN.hdf5\n",
      "Epoch 5/20\n",
      "8123/8123 [==============================] - 39s 5ms/step - loss: 1.0182 - top_k_categorical_accuracy: 0.9365 - categorical_accuracy: 0.7176 - val_loss: 3.1878 - val_top_k_categorical_accuracy: 0.5847 - val_categorical_accuracy: 0.2761\n",
      "\n",
      "Epoch 00005: val_top_k_categorical_accuracy improved from 0.56963 to 0.58467, saving model to ../Data/CNN.hdf5\n",
      "Epoch 6/20\n",
      "8123/8123 [==============================] - 39s 5ms/step - loss: 0.6701 - top_k_categorical_accuracy: 0.9732 - categorical_accuracy: 0.8071 - val_loss: 3.6109 - val_top_k_categorical_accuracy: 0.5585 - val_categorical_accuracy: 0.2504\n",
      "\n",
      "Epoch 00006: val_top_k_categorical_accuracy did not improve from 0.58467\n",
      "Epoch 7/20\n",
      "8123/8123 [==============================] - 39s 5ms/step - loss: 0.5105 - top_k_categorical_accuracy: 0.9878 - categorical_accuracy: 0.8526 - val_loss: 3.9087 - val_top_k_categorical_accuracy: 0.5099 - val_categorical_accuracy: 0.2280\n",
      "\n",
      "Epoch 00007: val_top_k_categorical_accuracy did not improve from 0.58467\n",
      "Epoch 8/20\n",
      "8123/8123 [==============================] - 39s 5ms/step - loss: 0.4694 - top_k_categorical_accuracy: 0.9866 - categorical_accuracy: 0.8656 - val_loss: 3.9669 - val_top_k_categorical_accuracy: 0.5192 - val_categorical_accuracy: 0.2436\n",
      "\n",
      "Epoch 00008: val_top_k_categorical_accuracy did not improve from 0.58467\n",
      "Epoch 9/20\n",
      "4864/8123 [================>.............] - ETA: 14s - loss: 0.3901 - top_k_categorical_accuracy: 0.9907 - categorical_accuracy: 0.8849"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs = 20, batch_size = 64, verbose = 1, shuffle=False, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1207
    },
    "colab_type": "code",
    "id": "fY_YIHuUqiYy",
    "outputId": "6fad0c3d-1f44-4c40-e3e8-9667aec7569d"
   },
   "outputs": [],
   "source": [
    "# plot metrics\n",
    "plt.figure(figsize=(8, 4), dpi=300)\n",
    "plt.title(\"Top 1 Accuracy: Tranning Set vs Test Set\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Top 1 Accuracy\")\n",
    "plt.plot(history.history['val_categorical_accuracy'], label=\"Test Set\")\n",
    "plt.plot(history.history['categorical_accuracy'], label=\"Trainning Set\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('CNNTop1.pdf', format='pdf', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NjqCSXDUWkJB"
   },
   "source": [
    "### Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1207
    },
    "colab_type": "code",
    "id": "Mi8_ek_5WkJC",
    "outputId": "81ae0f29-6c87-49f3-bd13-79294c71f16b"
   },
   "outputs": [],
   "source": [
    "# plot metrics\n",
    "plt.figure(figsize=(8, 4), dpi=300)\n",
    "plt.title(\"Top 5 Accuracy: Tranning Set vs Test Set\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Top 5 Accuracy\")\n",
    "plt.plot(history.history['top_k_categorical_accuracy'], label=\"Trainning Set\")\n",
    "plt.plot(history.history['val_top_k_categorical_accuracy'], label=\"Test Set\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('CNNTop5.pdf', format='pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1190
    },
    "colab_type": "code",
    "id": "fkGyPsUYpOGh",
    "outputId": "156144b9-eed7-4a6c-ba04-b9bb598bbac6"
   },
   "outputs": [],
   "source": [
    "# plot metrics\n",
    "plt.figure(figsize=(8, 4), dpi=300)\n",
    "plt.title(\"Tranning Loss vs Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(history.history['val_loss'], label=\"Test Set\")\n",
    "plt.plot(history.history['loss'], label=\"Trainning Set\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('CNNLoss.pdf', format='pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Dj6iSZeBPeg"
   },
   "source": [
    "### Save History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oVLXXsD6AlHW"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "  \n",
    "f = open('CNNHistory', 'wb')\n",
    "pickle.dump(history.history, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TF_Kay2VBu0y"
   },
   "source": [
    "### Load History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DlJJKCIWBx5s"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "f = open('CNNtHistory', 'rb')\n",
    "his = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "iNO7yo8GB7HR",
    "outputId": "875d83f0-cfed-47e7-c635-67ca36236ccb"
   },
   "outputs": [],
   "source": [
    "val_top_k = his['val_top_k_categorical_accuracy']\n",
    "print(\"top5: \", max(val_top_k))\n",
    "print(np.argmax(val_top_k))\n",
    "val_loss = his['val_loss']\n",
    "print(\"loss: \", min(val_loss))\n",
    "print(np.argmin(val_loss))\n",
    "val_ca = his['val_categorical_accuracy']\n",
    "print(\"top1: \", max(val_ca))\n",
    "print(np.argmax(val_ca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ryF6ey7iWkJG"
   },
   "source": [
    "### Model Save (delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCsgSU7WWkJG"
   },
   "outputs": [],
   "source": [
    "#model.save('ServeNet.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Cg4uj2iWkJI"
   },
   "source": [
    "### Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JPloAT10WkJI"
   },
   "outputs": [],
   "source": [
    "model = load_model('../Data/CNN.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "Q3TjZ5jxWkJJ",
    "outputId": "693bbdeb-fdc5-419d-d1d9-2b4e90615fc7"
   },
   "outputs": [],
   "source": [
    "print(\"Training set:\")\n",
    "loss_train, top5error_train, mae_train = model.evaluate(X_train, Y_train)\n",
    "print(\"Training accuracy = \", top5error_train)\n",
    "print('Test set:')\n",
    "loss_test, top5error_test, mae_test = model.evaluate(X_test, Y_test)\n",
    "print(\"Training accuracy = \", top5error_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TVLgMPzYWkJV"
   },
   "outputs": [],
   "source": [
    "# This code allows you to see the mislabelled examples\n",
    "C = 50\n",
    "# y_test_oh = np.eye(C)[Y_test.reshape(-1)]\n",
    "# X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
    "predY_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "5JiJEx8aaYdS",
    "outputId": "b8fb54fa-f78f-4ccf-f50c-f708710e2d10"
   },
   "outputs": [],
   "source": [
    "print(predY_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ncUXNBy3EJ_n",
    "outputId": "fc5f8d71-1921-4298-b114-35db1d229885"
   },
   "outputs": [],
   "source": [
    "print(np.argmax(predY_test[0]))\n",
    "print(np.argmax(Y_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "YccZO2X3WkJY",
    "outputId": "10a1035f-28f3-45d3-a935-b502ba5f3745"
   },
   "outputs": [],
   "source": [
    "# Heatmap Data\n",
    "non_onehot_pred_test = np.argmax(predY_test, axis=1)\n",
    "non_onehot_Y_test = np.argmax(Y_test, axis=1)\n",
    "categories = [\n",
    "\"eCommerce\",\n",
    "\"Photos\",\n",
    "\"Stocks\",\n",
    "\"Chat\",\n",
    "\"Telephony\",\n",
    "\"Medical\",\n",
    "\"Backend\",\n",
    "\"Travel\",\n",
    "\"Domains\",\n",
    "\"Data\",\n",
    "\"Internet of Things\",\n",
    "\"Transportation\",\n",
    "\"Government\",\n",
    "\"Marketing\",\n",
    "\"File Sharing\",\n",
    "\"Enterprise\",\n",
    "\"Cloud\",\n",
    "\"Games\",\n",
    "\"Financial\",\n",
    "\"Weather\",\n",
    "\"Payments\",\n",
    "\"Science\",\n",
    "\"Email\",\n",
    "\"Project Management\",\n",
    "\"Other\",\n",
    "\"Tools\",\n",
    "\"Database\",\n",
    "\"Storage\",\n",
    "\"Banking\",\n",
    "\"Application Development\",\n",
    "\"Real Estate\",\n",
    "\"Bitcoin\",\n",
    "\"Messaging\",\n",
    "\"Media\",\n",
    "\"Security\",\n",
    "\"Analytics\",\n",
    "\"Entertainment\",\n",
    "\"Images\",\n",
    "\"Video\",\n",
    "\"Sports\",\n",
    "\"Education\",\n",
    "\"News Services\",\n",
    "\"Search\",\n",
    "\"Shipping\",\n",
    "\"Music\",\n",
    "\"Events\",\n",
    "\"Reference\",\n",
    "\"Social\",\n",
    "\"Mapping\",\n",
    "\"Advertising\", \"All\"]\n",
    "\n",
    "print(non_onehot_pred_test.shape)\n",
    "print(non_onehot_Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute correct number on each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ncuV4zh0fcLd"
   },
   "outputs": [],
   "source": [
    "# Heat Map\n",
    "\n",
    "# cross = pd.crosstab(non_onehot_Y_test, non_onehot_pred_test.reshape(len(non_onehot_pred_test),), rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "cross = pd.crosstab(non_onehot_Y_test, non_onehot_pred_test, rownames=['Actual'], colnames=['Predicted'], margins=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "9UGi5GMri59H",
    "outputId": "698137ae-b499-4361-b303-9256cdce9b91"
   },
   "outputs": [],
   "source": [
    "cross.index = categories\n",
    "cross.index.name = \"Actual\"\n",
    "cross.columns = categories\n",
    "cross.columns.name = \"Predicted\"\n",
    "cross.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute category accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = cross[\"All\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "all = cross[\"All\"]\n",
    "\n",
    "for i in range(0, 50):\n",
    "    acc = cross.iloc[i,i] / all[i]\n",
    "    result.append(acc)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save acc in JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_category = dict(zip(categories, result)) \n",
    "\n",
    "import json\n",
    "with open('../Data/cnn_acc_category.json', 'w') as fp:\n",
    "    json.dump(acc_category, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1271
    },
    "colab_type": "code",
    "id": "TFXyXO7ziIuF",
    "outputId": "739c808b-f852-42d2-b2a9-f7cc069efaf9"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(35,20))\n",
    "\n",
    "sns.heatmap(cross, annot=True, vmin=0, fmt=\"d\", vmax=50, ax=ax, linewidths=.3, cmap=plt.cm.Blues)\n",
    "\n",
    "ax.xaxis.tick_top()\n",
    "ax.xaxis.set_label_position('top')\n",
    "\n",
    "\n",
    "plt.yticks(rotation=0) \n",
    "plt.xticks(rotation=90) \n",
    "\n",
    "plt.savefig('CNNHeatMap.pdf', format='pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "4.ServeNet-2D-CNN-1-BI-LTSM(512)-FC (Glove200b-trainedEmbeddingLayer).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
